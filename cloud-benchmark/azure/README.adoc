= Azure Auctionmark Benchmark

Contained within this folder are a number of things for setting up & running a cluster of containerized auctionmark running worker tasks on Azure Platform.

Within this README is the following:

* Instructions for setting up the docker image.
* How to setup the infra necessary on Azure.
* How to push the docker image to Azure.
* How to deploy the benchmark containers.

== Requirements

For local development, you will need the following:

* To run the various scripts and commands within this folder, you will need the `az` command line tool, and to be authenticated with it.
* `docker` available on your machine.
* `docker buildx` configured.
* `terraform` available on your machine.
* `kubectl` available on your machine.
* `helm` available on your machine.

=== Authenticating with Azure

Firstly, you want to login to Azure using the command line - this can be done by running:
```bash
az login --scope https://management.azure.com//.default
```

After this, you want to ensure that you are using the correct subscription - in our case, that will be "XTDB long-run reliability":
```bash
az account set --subscription "XTDB long-run reliability"
```

== Setting up the Azure Infra

All of the config for setting up the infrastructure on Azure is handled by Terraform - and the files are within the `terraform` directory. 

* The `main.tf` file contains the main configuration for the Azure resources.
* Can update the names of a few things within `terraform.tfvars` - though this is not expected to change so much from the default values. 

Prior to deploying any of the infra using terraform, you will need to initialize the terraform directory. From the `terraform` directory:
```bash
terraform init
```

To see what will will/change when running terraform, you can run:
```bash
terraform plan
```

To actually deploy the infra, you can run:
```bash
terraform apply
```

This will setup all of the azure resources we use and a base 

== Building & Pushing the Docker Image to Azure

To push the docker image to Azure, you will need to use the Azure Container Registry.

To login to the Azure Container Registry, you can run:
```bash
az acr login --name cloudbenchmarkregistry
```

You can then build & push the docker image for azure by running the following script:

```bash
./scripts/build-azure-bench.sh
```

This will:

* Creates a Shadow JAR of the `cloud-benchmark:azure` project.
** This contains the compiled `cloud-benchmark` project, which has a main file that runs auctionmark & configures it with provided node config, and also any of the dependencies we require to run the Azure module.
* Pushes the docker image to the Azure Container Registry.


== Deploying the Benchmark

Before trying to deploy the benchmark containers, you will need to ensure that you have the necessary permissions to deploy to the Kubernetes cluster. You can do this by running the following command:
```
az aks get-credentials --resource-group cloud-benchmark-resources --name cloud-benchmark-cluster
```

This will configure your `kubectl` to use the credentials for the Kubernetes cluster. 

Before deploying anything, must ensure all of the necessary pieces of config are set within the xtdb-config.yaml & match the values/names of the terraform architecture, run the following in the terraform directory:
```
terraform output
```

We must also ensure that we have both a namespace and a service account for the benchmark to run under. To create these, you can run the following:
```
kubectl create namespace cloud-benchmark
kubectl create serviceaccount xtdb-service-account --namespace cloud-benchmark 
```

=== Running Kafka

We require Kafka as the txLog for the multi-node benchmark. To use this, we need to setup the Kafka pods and the persistent volume claim for Kafka.

For this purpose, we use helm:
```
helm install kafka oci://registry-1.docker.io/bitnamicharts/kafka \
  --version 31.3.1 \
  --namespace cloud-benchmark \
  --set listeners.client.protocol=PLAINTEXT \
  --set listeners.controller.protocol=PLAINTEXT \
  --set controller.resourcesPreset=medium \
  --set controller.nodeSelector.nodepool=benchmark \
  --set controller.persistence.size=50Gi
```

To clearup the Kafka deployment, you can run:
```
helm uninstall kafka --namespace cloud-benchmark
```

To clearup the PVCs created by the Kafka deployment, you can run:
```
kubectl delete pvc data-kafka-controller-0 --namespace cloud-benchmark
kubectl delete pvc data-kafka-controller-1 --namespace cloud-benchmark
kubectl delete pvc data-kafka-controller-2 --namespace cloud-benchmark
```

=== Setting up the config for XTDB

The XTDB jobs rely on:

* A ConfigMap of environment variables for benchmark and platform settings
* A YAML-based ConfigMap for the XTDB node configuration

These must be present in the cloud-benchmark namespace before running any jobs:

```bash
kubectl apply -f kubernetes/xtdb-config.yaml
```

To update or refresh the configuration:

* Delete any existing jobs that are running, using the config.
* Re-apply the config by re-running the above command.

=== Running the loadphase:

Run the loadphase job by running the following command:
```bash
kubectl apply -f kubernetes/xtdb-load-phase.yaml
```

To see the logs of the loadphase job, you can run:
```bash
kubectl logs -f job/xtdb-load-phase --namespace cloud-benchmark
```

To delete the loadphase job, you can run:
```bash
kubectl delete job xtdb-load-phase --namespace cloud-benchmark
```

=== Running the multinode job:

Run the multinode job by running the following command:
```bash
kubectl apply -f kubernetes/xtdb-cluster-nodes.yaml
```

Since this job runs 3 pods in parallel, you'll need to check logs per pod. To list the pod names:
```bash
kubectl get pods --selector=job-name=xtdb-cluster-nodes --namespace cloud-benchmark
```

To see the logs of a multinode job, you can run:
```bash
kubectl logs -f <pod-name> --namespace cloud-benchmark
```

To delete the multinode job, you can run:
```bash
kubectl delete job xtdb-cluster-nodes --namespace cloud-benchmark
```

=== Clearing up

You can clearup the storage between runs by using the following:
```bash
./scripts/clear-azure-storage.sh
```

If you wish to clear up everything on kubernetes, use the following:
```bash
./scripts/clear-azure-bench.sh
```

== Monitoring with Grafana

Within here are also some provided templates for setting up a Grafana-Otel deployment which shall scrape the pods from the XTDB benchmark Job.

To deploy grafana, simply run:
```
kubectl apply -f kubernetes/grafana.yaml
```

To access the Grafana instance, you can use the external IP of the LoadBalancer service created for Grafana:
```bash
kubectl get svc grafana-service --namespace cloud-benchmark
```

The Grafana dashboard can be accessed via the external IP of the LoadBalancer service, on port `3001`. The default credentials are `admin`/`admin`.

With this up and runing, you can then import the XTDB dashboards (the cluster monitoring dashboard and node debugging dashboard) from `monitoring/grafana/dashboards`, and use these to monitor the benchmark pods.

=== Clearing up Grafana

If using the `clear-azure-bench.sh` script, by default we retain the Grafana deployment. If you wish to clear this up, you can run:

```bash
./scripts/clear-azure-bench --clear-grafana
```

This will clear up the Grafana deployment, the Grafana persistent volume claim, and the Prometheus persistent volume claim.

== Monitoring With Azure Monitor

=== Setup

To monitor the benchmark, we can use Azure Application Insights. We set up an applications insights resource in the terraform configuration, and output a connection string.

=== Collecting metrics from node

To see the benchmark metrics you need to supply an application insights connection string via an environment variable in the `single-node-auctionmark.yaml` or `multi-node-auctionmark.yaml` file as below:

```yaml
apiVersion: "v1"
kind: "ConfigMap"
metadata:
  ...
data:
  XTDB_AZURE_APP_INSIGHTS_CONNECTION_STRING: "<connection-string>"
  ...
```

You can retrieve the connection_string from terraform state as follows:

```bash
terraform output -raw insights_connection_string
```

After a while you should be able to see the metrics in the Azure portal under the Application Insights resource, navigating to Monitoring > Metrics and looking under Metric Namespace > Custom.

=== Observing metrics in the Dashboard

We have made a custom dashboard for various XTDB, JVM and auctionmark metrics that we care about, with the ability to split them by node.

To setup the dashboard itself, there's a few steps we must take:

* Before anything else - ensure we can filter/split custom metrics. This can be found under the `usage and estimated costs` section of the Application Insights resource, and we should update this to allow "Alerting on Custom Metric Dimensions".
* With that setup, we can create our custom dashboard.
** Got to `Application Dashbard` on the Application Insights resource.
** Create a new custom dashboard.
** We can upload this from a template - you can use the template found within the `cloud-benchmark/azure` directory, `application-insights/dashboard.json`. 

We already have a shared dashboard setup, under "Monitoring Dashboard"
